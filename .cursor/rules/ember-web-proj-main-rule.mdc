---
alwaysApply: true
---

# Ember Amp Web - Cursor Rules

## Project Identity
- **Name:** Ember Amp Web
- **Purpose:** Browser-based HiFi amplifier simulator with real-time DSP processing
- **Target:** Audiophiles who want analog warmth simulation for their PC audio
- **Core principle:** All audio processing happens 100% locally in the browser - zero server-side audio handling

## Tech Stack (Strict)
- React 18 + TypeScript (strict mode)
- Vite for build/dev
- Web Audio API (native, no libraries)
- AudioWorklet for custom DSP (never ScriptProcessorNode)
- Zustand for state management
- Tailwind CSS + custom CSS for UI
- No external audio processing libraries (no Tone.js, no Pizzicato, etc.)

## Code Style

### TypeScript
- Strict mode enabled, no `any` types
- Explicit return types on all functions
- Interface over type for object shapes
- Descriptive variable names (no single letters except loops)
- All audio parameters typed explicitly:
```typescript
interface AudioParams {
  gainDb: number;      // Always in dB, convert to linear when needed
  frequency: number;   // Always in Hz
  q: number;           // Quality factor
  ratio: number;       // Compression ratio (e.g., 4 for 4:1)
}
```

### React Components
- Functional components only, no classes
- Custom hooks for all audio logic (`useAudioInput`, `useAudioAnalyser`, etc.)
- Memoize expensive computations with `useMemo`
- Use `useCallback` for event handlers passed to children
- Component files: PascalCase (`Knob.tsx`, `VUMeter.tsx`)
- One component per file

### File Naming
- Components: `PascalCase.tsx`
- Hooks: `useCamelCase.ts`
- Utils: `kebab-case.ts`
- Types: `*.types.ts`
- Audio nodes: `PascalCaseNode.ts`
- Worklets: `kebab-case.worklet.js` (must be JS for AudioWorklet)

## Audio Engine Architecture

### Singleton Pattern
```typescript
// AudioEngine.ts
class AudioEngine {
  private static instance: AudioEngine;
  private ctx: AudioContext | null = null;
  
  static getInstance(): AudioEngine {
    if (!AudioEngine.instance) {
      AudioEngine.instance = new AudioEngine();
    }
    return AudioEngine.instance;
  }
  
  // Never create AudioContext in constructor - wait for user interaction
  async initialize(): Promise<void> {
    this.ctx = new AudioContext();
    await this.loadWorklets();
  }
}
```

### Node Wrapper Pattern
Each DSP processor should be a class wrapping Web Audio nodes:
```typescript
// Example: ToneStackNode.ts
class ToneStackNode {
  private bassFilter: BiquadFilterNode;
  private midFilter: BiquadFilterNode;
  private trebleFilter: BiquadFilterNode;
  
  constructor(ctx: AudioContext) {
    this.bassFilter = ctx.createBiquadFilter();
    this.bassFilter.type = 'lowshelf';
    this.bassFilter.frequency.value = 100;
    // ... setup chain
  }
  
  connect(destination: AudioNode): void {
    this.trebleFilter.connect(destination);
  }
  
  disconnect(): void {
    this.trebleFilter.disconnect();
  }
  
  setBass(db: number): void {
    this.bassFilter.gain.value = db;
  }
}
```

### Parameter Conventions
- All gain values stored in **dB** in state
- Convert to linear only when setting Web Audio node values:
```typescript
const dbToLinear = (db: number): number => Math.pow(10, db / 20);
const linearToDb = (linear: number): number => 20 * Math.log10(linear);
```
- Frequency always in Hz
- Time always in seconds (not ms)
- Use `setTargetAtTime()` for smooth parameter changes, not direct `.value` assignment

## AudioWorklet Rules

### File Location
Worklet files MUST be in `public/worklets/` and be plain JavaScript (not TypeScript).

### Worklet Structure
```javascript
// public/worklets/tube-saturation.worklet.js
class TubeSaturationProcessor extends AudioWorkletProcessor {
  static get parameterDescriptors() {
    return [
      { name: 'drive', defaultValue: 0.5, minValue: 0, maxValue: 1 }
    ];
  }
  
  process(inputs, outputs, parameters) {
    const input = inputs[0];
    const output = outputs[0];
    const drive = parameters.drive;
    
    // Process audio...
    
    return true; // Keep processor alive
  }
}

registerProcessor('tube-saturation', TubeSaturationProcessor);
```

### Loading Worklets
```typescript
await ctx.audioWorklet.addModule('/worklets/tube-saturation.worklet.js');
const node = new AudioWorkletNode(ctx, 'tube-saturation');
```

## State Management (Zustand)

### Store Structure
```typescript
interface AudioState {
  // Status
  isInitialized: boolean;
  isRunning: boolean;
  inputDeviceId: string | null;
  
  // Parameters (all in dB where applicable)
  inputGain: number;
  bass: number;
  mid: number;
  treble: number;
  presence: number;
  drive: number;        // 0-1, not dB
  outputGain: number;
  
  // Bypass states
  bypassToneStack: boolean;
  bypassSaturation: boolean;
  bypassCompressor: boolean;
  
  // Presets
  currentPreset: string | null;
  
  // Actions
  setParameter: (param: keyof AudioState, value: number | boolean) => void;
  loadPreset: (presetId: string) => void;
  initialize: () => Promise<void>;
  start: () => Promise<void>;
  stop: () => void;
}
```

### Never store AudioNodes in Zustand
Audio nodes are not serializable. Store only primitive values. Keep node references in AudioEngine class.

## UI Components

### Knob Component Requirements
- Drag interaction (vertical or circular)
- Double-click to reset to default
- Value display (formatted appropriately)
- Min/max/step props
- onChange callback with value in display units (dB, Hz, etc.)
- Keyboard accessibility (arrow keys to adjust)

### VU Meter Requirements
- RequestAnimationFrame loop for smooth animation
- Peak hold with decay
- RMS and Peak display options
- Configurable range (-60dB to +6dB typical)
- Analog-style ballistics (attack ~10ms, release ~300ms)

### Styling
- Dark theme primary: `#1a1a1a`
- Warm accent: `#ff6b35`
- Glow/active: `#ffaa00`
- Text: `#e0e0e0`
- Subtle grain texture on backgrounds
- Skeuomorphic knobs with CSS gradients/shadows
- Smooth transitions (150-300ms)

## Error Handling

### getUserMedia Errors
Always handle these cases:
- Permission denied
- No audio input devices
- Device in use by another app
- Browser not supported

```typescript
try {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
} catch (err) {
  if (err instanceof DOMException) {
    switch (err.name) {
      case 'NotAllowedError':
        // User denied permission
        break;
      case 'NotFoundError':
        // No audio input device
        break;
      case 'NotReadableError':
        // Device in use
        break;
    }
  }
}
```

### AudioContext State
Always check and handle AudioContext state:
```typescript
if (ctx.state === 'suspended') {
  await ctx.resume();
}
```

## Performance Guidelines

- Use `AnalyserNode.getFloatTimeDomainData()` over `getByteTimeDomainData()` for accuracy
- Throttle UI updates to 60fps max (use requestAnimationFrame)
- Don't create new nodes on every render - create once, update parameters
- Use `setTargetAtTime()` with small time constants for smooth parameter automation
- Disconnect and cleanup nodes on unmount

## Comments and Documentation

### JSDoc for public methods
```typescript
/**
 * Sets the bass EQ gain
 * @param db - Gain in decibels (-12 to +12)
 */
setBass(db: number): void {
  this.bassFilter.gain.setTargetAtTime(db, this.ctx.currentTime, 0.01);
}
```

### Inline comments for DSP math
```typescript
// Soft clipping using tanh-based saturation
// drive: 0-1, higher = more harmonics
const saturate = (sample: number, drive: number): number => {
  const k = 2 * drive / (1 - drive + 0.001); // Avoid division by zero
  return Math.tanh(k * sample) / Math.tanh(k); // Normalize output
};
```

## Don't

- ❌ Don't use `ScriptProcessorNode` (deprecated, main thread blocking)
- ❌ Don't create multiple `AudioContext` instances
- ❌ Don't use `any` type
- ❌ Don't store audio node references in React state or Zustand
- ❌ Don't use `setInterval` for audio metering (use rAF)
- ❌ Don't assign `.value` directly for smooth changes (use `setTargetAtTime`)
- ❌ Don't forget cleanup in useEffect returns
- ❌ Don't hardcode device IDs
- ❌ Don't use external audio libraries

## Do

- ✅ Initialize AudioContext only after user interaction
- ✅ Use TypeScript strict mode
- ✅ Handle all error cases for getUserMedia
- ✅ Use AudioWorklet for custom DSP
- ✅ Store all gain in dB, convert to linear when needed
- ✅ Cleanup nodes on component unmount
- ✅ Use requestAnimationFrame for UI updates
- ✅ Enumerate devices and let user select
- ✅ Provide clear feedback for setup steps (virtual cable guide)

## Git Commit Style
```
feat: add tube saturation worklet with harmonic generation
fix: resolve AudioContext suspension on tab switch  
refactor: extract tone stack into separate node class
docs: add virtual audio cable setup guide
style: update knob component with amber glow effect
```

## Testing Priorities
1. Audio routing works (input → output passthrough)
2. Each DSP node processes correctly
3. Parameters update smoothly without clicks
4. Presets load and apply correctly
5. Cleanup happens properly on unmount
6. Error states handled gracefully
